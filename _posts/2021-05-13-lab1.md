---
layout: post
title: 6.824 lab1 MapReduce的实现
date: 2021-05-13
Author: yufeng 
tags: [Hadoop]
comments: true
toc: true
---

## 6.824中lab1的具体实现

#### MapReduce中的结构

* coordinator的结构设计

  ```go
  type Coordinator struct {
  	// Your definitions here.
  	inputFiles []string		// 输入给MapReduce作业的输入文件
  	nReduces int			// 分区个数
  	mapTasks []MapReduceTask	// map任务队列
  	reduceTasks []MapReduceTask	// reduce任务队列
  	mapFinished bool		// 判断map任务是否都完成
  	reduceFinished bool		// 判断reduce任务是否都完成
  	mutex sync.Mutex		// 为了保证worker的并发，给coordinator加锁
  }
  
  type MapReduceTask {
      Type string		// 表明该任务的类型为map，reduce或者wait
  	State int	//  0为未分配，1为已分配，2为已完成
  	Index int		// 在任务队列中的索引
  	StartTime time.Time		// 启动时间
  	InputFile string		// 给map任务的输入文件
  	InterNum int		// 中间文件数量
  }
  ```

* worker与coordinator交互的rpc请求与响应实例

  ```go
  const (
  	RequestTask = iota
  	FinishTask
  )
  
  type MapReduceArgs struct {
  	MessageType int
  	Task MapReduceTask
  }
  
  type MapReduceReply struct {
  	Task MapReduceTask
  	NReduces int
  }
  ```

#### 该MapReduce的流程

1. 启动mrcoordinator进行初始化coordinator，并将mapTasks和reduceTasks进行初始化，启动一个线程监听从Worker来的RPC请求

2. 启动worker，让worker循环给coordinator发送RequestTask请求，若没有任务空闲，则让worker等待1秒后发请求

   ```go
   for true {
   		args := MapReduceArgs{}
   		args.MessageType = RequestTask
   
   		reply := MapReduceReply{}
   
   		res := call("Coordinator.WorkerHandler", &args, &reply)
   		if !res {
   			break
   		}
   
   		switch reply.Task.Type {
   		case "Map":
   			doMap(&reply, mapf)
   		case "Reduce":
   			doReduce(&reply, reducef)
   		case "Wait":
   			time.Sleep(time.Second)
   		}
   	}
   ```

3. Coordinator调用WorkerHandler函数来响应worker的请求，由于发送的是RequestTask，因此messageType为0，给worker发送响应：

   * 如果要等待的话，则新建个任务，赋予type属性为Wait，让worker等待
   * 再判断map任务是否都完成，若没有都完成，则将mapTasks里的未分配任务或者已分配但worker处理时间大于10s的任务重新分配给另一个worker，并更新mapTask的相关属性
   * 若map任务已经完成，则进行reduceTask的分配，并更新reduceTask相关属性

   ```go
   if WorkerWaiting(c) {
   			reply.Task = MapReduceTask{
   				Type: "Wait",
   			}
   			return nil
   		}
   		if !c.mapFinished {
   			for i := 0; i < len(c.inputFiles); i++ {
   				if c.mapTasks[i].State == 0 || (c.mapTasks[i].State == 1 && time.Since(c.mapTasks[i].StartTime) > 10*time.Second) {
   					task := &c.mapTasks[i]
   					task.StartTime = time.Now()
   					task.State = 1
   
   					reply.NReduces = c.nReduces
   					reply.Task = *task
   					return nil
   				}
   			}
   			
   		} else {
   			if !c.reduceFinished {
   				for i:=0; i < c.nReduces; i++ {
   					if c.reduceTasks[i].State == 0 || (c.reduceTasks[i].State == 1 && time.Since(c.reduceTasks[i].StartTime) > 10*time.Second) {
   						task := &c.reduceTasks[i]
   						task.StartTime = time.Now()
   						task.State = 1
   						reply.NReduces = c.nReduces
   						reply.Task = *task
   						return nil
   					}
   				}
   			}
   		}
   ```

4. Worker得到了coordinator的响应后，根据任务类型，执行不同的函数，首先是doMap()的执行:

   * 打开输入文件，执行map任务得到kv键值对数组，并对数组进行分区，默认使用ihash来分区
   * 将键值对写入中间临时文件，键值对为{"单词",1}
   * 发送FinishTask请求，将处理完的任务发给coordinator进行处理

5. Coordinator处理FinishTask请求，并更新mapFinished和reduceFinished的状态

   ```go
   messageType := args.MessageType
   switch messageType {	
   case 1:
   		task := args.Task
   		task.State = 2
   
   		if c.mapFinished {
   			c.reduceTasks[task.Index] = task
   			fmt.Printf("任务%v完成 \n", task.Index)
   			for _, v := range c.reduceTasks {
   				if v.State != 2 {
   					return nil
   				}
   			}
   
   			c.reduceFinished = true
   		} else {
   			c.mapTasks[task.Index] = task
   			for _, v := range c.mapTasks {
   				if v.State != 2 {
   					return nil
   				}
   			}
   			c.mapFinished = true
   		}
   }
   ```

6. 当Map任务都处理完成后，当Worker发送RequestTask请求时，Coordinator响应请求将reduceTask分配给Worker，Worker进行reduce任务的处理:

   * 打开该分区的中间临时文件，获取并合并每个临时文件的键值对，将键值对按照键的大小来进行排序，形成分区内有序的键值对。
   * 进行reduce任务的操作，取得相同键的值，并把值进行相加，最终把输出结果输出到最终的输出文件中
   * 当所有临时文件处理完毕后，发送FinishTask请求给Coordinator，并将处理完的reduce任务发送给Coordinator

7. 最后当所有任务处理完毕，Coordinator关闭rpc连接

#### **通过所有测试**

源代码：https://github.com/zhanziwei/6.824

#### 参考资料

https://blog.imfing.com/2020/09/mit-6.824-lab1-map-reduce/

[MapReduce: simplified data processing on large clusters](https://dl.acm.org/doi/abs/10.1145/1327452.1327492)

