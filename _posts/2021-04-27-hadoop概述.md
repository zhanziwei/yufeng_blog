---
layout: post
title: Hadoop概述
date: 2021-04-27
Author: yufeng 
tags: [Hadoop]
comments: true
toc: true
---

## Hadoop概述

Hadoop是一种分布式数据存储系统，是一种用来处理海量数据的非关系型数据库，里面有四大组件，分别是HDFS、Yarn和MapReduce，HDFS是分布式的文件系统，Yarn是资源调度器，而MapReduce则是分布式的计算框架；Common则是以上三大组件的底层支撑组件，主要提供基础工具包和RPC框架。

#### Hadoop优势

1. 高可靠性
2. 高扩展性
3. 高效性
4. 高容错性

#### Hadoop的序列化

序列化是指将结构化对象转换为二进制字节流以便于在网络上的传输或写入磁盘进行存储；而反序列化则是进行相反的操作。序列化一般用于进程间通信和永久存储。

Hadoop不用Java的序列化，因为Java的序列化是一个重量级序列化框架，一个对象被序列化后，会附带很多额外的信息，不便于网络中高效传输，因此使用自己的Writable进行序列化。

#### Hadoop序列化特点

1. 紧凑：高效使用存储空间
2. 快速：读写数据的额外开销小
3. 互操作：支持多语言的交互

#### 具体实现bean对象实现序列化接口

1. 实现Writable接口
2. 反序列化时，需要反射调用空参构造函数
3. 重写序列化方法
4. 重写反序列化方法
5. 注意反序列化的顺序和序列化的顺序完全一致
6. 要想把结果显示在文件中，需要重写toString()，可用"\t"分开，方便后续用。
7. 如果需要将自定义的bean放在key中传输，则还需要实现Comparable接口，因为MapReduce框中的Shuffle过程要求对key必须能排序。

```java
import org.apache.hadoop.io.Writable;

import java.io.DataInput;
import java.io.DataOutput;
import java.io.IOException;

public class FlowBean implements Writable {
    private long upFlow;
    private long downFlow;
    private long sumFlow;

    public long getUpFlow() {
        return upFlow;
    }

    public void setUpFlow(long upFlow) {
        this.upFlow = upFlow;
    }

    public long getDownFlow() {
        return downFlow;
    }

    public void setDownFlow(long downFlow) {
        this.downFlow = downFlow;
    }

    public long getSumFlow() {
        return sumFlow;
    }

    public void setSumFlow(long sumFlow) {
        this.sumFlow = sumFlow;
    }

    @Override
    public void write(DataOutput dataOutput) throws IOException {
        dataOutput.writeLong(upFlow);
        dataOutput.writeLong(downFlow);
        dataOutput.writeLong(sumFlow);
    }

    @Override
    public void readFields(DataInput dataInput) throws IOException {
        this.upFlow = dataInput.readLong();
        this.downFlow = dataInput.readLong();
        this.sumFlow = dataInput.readLong();
    }

    @Override
    public String toString() {
        return upFlow + "\t" + downFlow + "\t" + sumFlow;
    }
}
```

