---
layout: post
title: MapReduce论文
date: 2021-05-09
Author: yufeng 
tags: [Hadoop]
comments: true
toc: true
---

## MapReduce：在大型集群上简化数据处理

#### 研究意义

在过去的五年里，作者和许多其他人在谷歌已经实现了数百个处理大量原始数据(如爬行文档、web请求日志等)的专用计算，以计算各种派生数据，例如倒排索引，各种web文档图结构的表示，每个主机抓取的页面数的摘要。大多数这样的计算在概念上是简单的，然而输入数据通常很大，计算必须分布在数百或数千台机器上，以便在合理的时间内完成。如何并行化计算、分布数据和处理失败的问题，会用大量复杂的代码掩盖最初的简单计算，以处理这些问题。

MapReduce的抽象是受到Lisp和许多其他函数式语言中的map和reduce原语的启发。大部分计算涉及在我们的计算中对于每个逻辑record使用map操作，为了计算一组中间键值对，然后运用reduce操作应用于所有共享相同key的value，以便于适当地组合派生数据。

这项工作的主要贡献是一个简单而强大的接口，使大规模计算的自动并行化和分布成为可能，并结合该接口的实现在商用pc的大型集群上实现高性能。

#### 研究内容

由用户编写的Map接受一个输入对，并产生一组中间键/值对。MapReduce库将与相同的中间键I关联的所有中间值分组，并将它们传递给Reduce函数。

Reduce函数接受中间键I和该键的一组值。将这些值合并在一起，形成一组更小的值。每次reduce调用只产生0或1个输出值，中间值通过迭代器提供给用户的reduce函数，使得我们处理那些太大无法装入内存的值列表。

#### 实现方式

##### 执行流程

通过自动地将输入数据进行分区为M个切片，Map调用分布在多台机器上。输入分割可以由不同的机器并行处理。Reduce调用通过使用分区函数（例如hash函数取得索引）将中间键空间划分为R块来进行分配。分区的数量和分区函数由用户指定。

![img](https://user-gold-cdn.xitu.io/2019/6/10/16b3fe038e971db4?imageView2/0/w/1280/h/960/format/webp/ignore-error/1)

1. MapReduce将输入文件分割为M个切片，然后在一组机器上启动该程序的多个副本
2. 由1个Master控制多个worker组成，Master将map或者reduce任务分配给空闲的worker
3. 一个被分配map任务的worker读取相应输入分割的内容，它从输入数据中解析键值对，并将每个键值对传递给用户定义的map函数。Map函数产生的中间键值对被缓冲在内存中
4. 缓存定期写入本地磁盘，由分区函数划分为R个区域，这些缓存在本地磁盘的位置被传递给主服务器，主服务器负责将位置转发给reduce worker。
5. reduce worker使用远程过程调用从map worker的本地磁盘读取缓冲数据。当reduce worker读取了所有中间数据时，根据中间键对数据进行排序，以便所有出现的相同键都被分组在一起。之所以需要进行排序，是因为通常有许多不同的键映射到相同的reduce任务。如果中间数据量太大，无法装入内存，则使用外部排序。
6. reduce工作器遍历已排序的中间数据，对于遇到的每个唯一中间键，它将键和相应的中间值集传递给用户的reduce函数。Reduce函数的输出被附加到这个Reduce分区的最终输出文件中
7. 当所有的map任务和reduce任务都完成后，主程序唤醒用户程序。此时，用户程序中的MapReduce调用返回给用户代码。

成功运行后，mapreduce的输出在R个输出文件中，可将该输出作为输入传递给另一个MapReduce调用或从另一个分布式应用程序中使用它们，该应用程序能够处理划分为多个文件的输入。

##### Master 的数据结构

对于每个map任务和reduce任务，存储状态和对无空闲的worker的标志。

Master是将中间文件区域位置从map任务传播到reduce任务的管道。对于每个完成的map任务，master存储由map任务生成的R中间文件区域的位置和大小。当完成map任务，接受对该位置和大小位置的更新。信息被推送到正在执行reduce的worker中。

##### 容错性

由于MapReduce库的设计目的是帮助使用数百或数千台机器处理大量数据，因此该库必须优雅地容忍机器故障。

* Worker 失败

  master会周期性地ping每一个worker。如果在一定的时间内没有收到来自工作人员的响应，则主服务器将该工作人员标记为失败。任何由该worker完成的map任务都将被重置为其初始空闲状态，因此可以对其他worker进行调度。类似地，一个失败的worker上的任何正在进行的map任务或reduce任务也会被重置为空闲，并有资格重新调度。

  当出现故障时，将重新执行已完成的map任务。当Aworker执行map任务失败时，将任务给B执行，执行reduce任务的worker被通知重新执行。任何还没有从workerA读取数据的reduce任务都从workerB读取数据

* Master 失败

  如果主任务死亡，则可以从最后一个检查点状态启动一个新的副本。然而，鉴于只有一个master，它的失败是不太可能的;因此，如果master失败，我们当前的实现将中止MapReduce计算。客户端可以检查这个条件并重试MapReduce操作。

* 在错误面前的处理机制

  分布式实现的输出和临时输出是确定的输出。依赖于对Map和Reduce任务的输出进行原子提交来完成该性质。每个worker中的任务把它的输出写到私有临时文件中。当一个map任务完成时，worker发送消息给master，在该消息中包含这R个临时文件的名字。如果master从一个已经完成的map任务再次收到一个完成的消息,它将忽略这个消息.否则,它在master的数据结构里记录这R个文件的名字。

  当Reduce任务完成时，把临时文件重命名为最终的输出文件，依赖由底层文件系统提供的原子重命名操作来保证,最终的文件系统状态仅仅包含一个reduce任务产生的数据。

##### 存储位置

计算机环境里,网络带宽是一个相当缺乏的资源.我们利用把输入数据(由GFS管理)存储在机器的本地磁盘上来保存网络带宽.GFS把每个文件分成64MB的一些块,然后每个块的几个拷贝存储在不同的机器上(一般是3个拷贝)。master考虑输入文件的位置信息,并且努力在一个包含相关输入数据的机器上安排一个map任务.如果这样做失败了,它尝试在那个任务的输入数据的附近安排一个map任务。

#### 技巧

##### 分割函数

默认使用hash方法分割，也可以自定义分割函数

##### 顺序保证

保证在一个给定的分割里，中间的键值对以key递增的顺序处理。使每个分区产生一个有序的输出文件

##### Combiner函数

在每一个执行map任务的机器上combiner函数被执行.一般的,相同的代码被用在combiner和reduce函数.在combiner和reduce函数之间唯一的区别是MapReduce库怎样控制函数的输出.reduce函数的输出被保存最终输出文件里.combiner函数的输出被写到中间文件里,然后被发送给reduce任务.

##### 输入输出类型

支持以几种不同的格式读取输入数据

##### 附带作用

可以在map或reduce操作时，产生辅助文件作为一个附加的输出

##### 状态信息

master运行一个HTTP服务器,并且可以输出一组状况页来供人们使用.状态页显示计算进度,象多少个任务已经完成,多少个还在运行,输入的字节数,中间数据字节数,输出字节数,处理百分比,等等.这个页也包含到标准错误的链接,和由每个任务产生的标准输出的链接.用户可以根据这些数据预测计算需要花费的时间,和是否需要更多的资源.当计算比预期的要慢很多的时候,这些页面也可以被用来判断是不是这样.

##### 计数器

MapReduce库提供一个计数器工具,来计算各种事件的发生次数